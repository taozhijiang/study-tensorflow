// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/prediction_log.proto

#include "tensorflow_serving/apis/prediction_log.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// This is a temporary google only hack
#ifdef GOOGLE_PROTOBUF_ENFORCE_UNIQUENESS
#include "third_party/protobuf/version.h"
#endif
// @@protoc_insertion_point(includes)

namespace protobuf_tensorflow_5fserving_2fapis_2fclassification_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fclassification_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_ClassificationRequest;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fclassification_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_ClassificationResponse;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2fclassification_2eproto
namespace protobuf_tensorflow_5fserving_2fapis_2finference_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2finference_2eproto ::google::protobuf::internal::SCCInfo<1> scc_info_MultiInferenceResponse;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2finference_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_MultiInferenceRequest;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2finference_2eproto
namespace protobuf_tensorflow_5fserving_2fapis_2fpredict_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fpredict_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_PredictRequest;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fpredict_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_PredictResponse;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2fpredict_2eproto
namespace protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_ClassifyLog;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_MultiInferenceLog;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_PredictLog;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_RegressLog;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_SessionRunLog;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto
namespace protobuf_tensorflow_5fserving_2fapis_2fregression_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fregression_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_RegressionRequest;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fregression_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_RegressionResponse;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2fregression_2eproto
namespace protobuf_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto ::google::protobuf::internal::SCCInfo<3> scc_info_SessionRunRequest;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto ::google::protobuf::internal::SCCInfo<3> scc_info_SessionRunResponse;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto
namespace protobuf_tensorflow_5fserving_2fcore_2flogging_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fcore_2flogging_2eproto ::google::protobuf::internal::SCCInfo<2> scc_info_LogMetadata;
}  // namespace protobuf_tensorflow_5fserving_2fcore_2flogging_2eproto
namespace tensorflow {
namespace serving {
class ClassifyLogDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<ClassifyLog>
      _instance;
} _ClassifyLog_default_instance_;
class RegressLogDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<RegressLog>
      _instance;
} _RegressLog_default_instance_;
class PredictLogDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<PredictLog>
      _instance;
} _PredictLog_default_instance_;
class MultiInferenceLogDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<MultiInferenceLog>
      _instance;
} _MultiInferenceLog_default_instance_;
class SessionRunLogDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<SessionRunLog>
      _instance;
} _SessionRunLog_default_instance_;
class PredictionLogDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<PredictionLog>
      _instance;
  const ::tensorflow::serving::ClassifyLog* classify_log_;
  const ::tensorflow::serving::RegressLog* regress_log_;
  const ::tensorflow::serving::PredictLog* predict_log_;
  const ::tensorflow::serving::MultiInferenceLog* multi_inference_log_;
  const ::tensorflow::serving::SessionRunLog* session_run_log_;
} _PredictionLog_default_instance_;
}  // namespace serving
}  // namespace tensorflow
namespace protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto {
static void InitDefaultsClassifyLog() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_ClassifyLog_default_instance_;
    new (ptr) ::tensorflow::serving::ClassifyLog();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::ClassifyLog::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<2> scc_info_ClassifyLog =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsClassifyLog}, {
      &protobuf_tensorflow_5fserving_2fapis_2fclassification_2eproto::scc_info_ClassificationRequest.base,
      &protobuf_tensorflow_5fserving_2fapis_2fclassification_2eproto::scc_info_ClassificationResponse.base,}};

static void InitDefaultsRegressLog() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_RegressLog_default_instance_;
    new (ptr) ::tensorflow::serving::RegressLog();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::RegressLog::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<2> scc_info_RegressLog =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsRegressLog}, {
      &protobuf_tensorflow_5fserving_2fapis_2fregression_2eproto::scc_info_RegressionRequest.base,
      &protobuf_tensorflow_5fserving_2fapis_2fregression_2eproto::scc_info_RegressionResponse.base,}};

static void InitDefaultsPredictLog() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_PredictLog_default_instance_;
    new (ptr) ::tensorflow::serving::PredictLog();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::PredictLog::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<2> scc_info_PredictLog =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsPredictLog}, {
      &protobuf_tensorflow_5fserving_2fapis_2fpredict_2eproto::scc_info_PredictRequest.base,
      &protobuf_tensorflow_5fserving_2fapis_2fpredict_2eproto::scc_info_PredictResponse.base,}};

static void InitDefaultsMultiInferenceLog() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_MultiInferenceLog_default_instance_;
    new (ptr) ::tensorflow::serving::MultiInferenceLog();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::MultiInferenceLog::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<2> scc_info_MultiInferenceLog =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsMultiInferenceLog}, {
      &protobuf_tensorflow_5fserving_2fapis_2finference_2eproto::scc_info_MultiInferenceRequest.base,
      &protobuf_tensorflow_5fserving_2fapis_2finference_2eproto::scc_info_MultiInferenceResponse.base,}};

static void InitDefaultsSessionRunLog() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_SessionRunLog_default_instance_;
    new (ptr) ::tensorflow::serving::SessionRunLog();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::SessionRunLog::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<2> scc_info_SessionRunLog =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 2, InitDefaultsSessionRunLog}, {
      &protobuf_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto::scc_info_SessionRunRequest.base,
      &protobuf_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto::scc_info_SessionRunResponse.base,}};

static void InitDefaultsPredictionLog() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_PredictionLog_default_instance_;
    new (ptr) ::tensorflow::serving::PredictionLog();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::PredictionLog::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<6> scc_info_PredictionLog =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 6, InitDefaultsPredictionLog}, {
      &protobuf_tensorflow_5fserving_2fcore_2flogging_2eproto::scc_info_LogMetadata.base,
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_ClassifyLog.base,
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_RegressLog.base,
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_PredictLog.base,
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_MultiInferenceLog.base,
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_SessionRunLog.base,}};

void InitDefaults() {
  ::google::protobuf::internal::InitSCC(&scc_info_ClassifyLog.base);
  ::google::protobuf::internal::InitSCC(&scc_info_RegressLog.base);
  ::google::protobuf::internal::InitSCC(&scc_info_PredictLog.base);
  ::google::protobuf::internal::InitSCC(&scc_info_MultiInferenceLog.base);
  ::google::protobuf::internal::InitSCC(&scc_info_SessionRunLog.base);
  ::google::protobuf::internal::InitSCC(&scc_info_PredictionLog.base);
}

::google::protobuf::Metadata file_level_metadata[6];

const ::google::protobuf::uint32 TableStruct::offsets[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::ClassifyLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::ClassifyLog, request_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::ClassifyLog, response_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::RegressLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::RegressLog, request_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::RegressLog, response_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::PredictLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::PredictLog, request_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::PredictLog, response_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::MultiInferenceLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::MultiInferenceLog, request_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::MultiInferenceLog, response_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionRunLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionRunLog, request_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::SessionRunLog, response_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::PredictionLog, _internal_metadata_),
  ~0u,  // no _extensions_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::PredictionLog, _oneof_case_[0]),
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::PredictionLog, log_metadata_),
  offsetof(::tensorflow::serving::PredictionLogDefaultTypeInternal, classify_log_),
  offsetof(::tensorflow::serving::PredictionLogDefaultTypeInternal, regress_log_),
  offsetof(::tensorflow::serving::PredictionLogDefaultTypeInternal, predict_log_),
  offsetof(::tensorflow::serving::PredictionLogDefaultTypeInternal, multi_inference_log_),
  offsetof(::tensorflow::serving::PredictionLogDefaultTypeInternal, session_run_log_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::PredictionLog, log_type_),
};
static const ::google::protobuf::internal::MigrationSchema schemas[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, sizeof(::tensorflow::serving::ClassifyLog)},
  { 7, -1, sizeof(::tensorflow::serving::RegressLog)},
  { 14, -1, sizeof(::tensorflow::serving::PredictLog)},
  { 21, -1, sizeof(::tensorflow::serving::MultiInferenceLog)},
  { 28, -1, sizeof(::tensorflow::serving::SessionRunLog)},
  { 35, -1, sizeof(::tensorflow::serving::PredictionLog)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_ClassifyLog_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_RegressLog_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_PredictLog_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_MultiInferenceLog_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_SessionRunLog_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_PredictionLog_default_instance_),
};

void protobuf_AssignDescriptors() {
  AddDescriptors();
  AssignDescriptors(
      "tensorflow_serving/apis/prediction_log.proto", schemas, file_default_instances, TableStruct::offsets,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_PROTOBUF_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 6);
}

void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
      "\n,tensorflow_serving/apis/prediction_log"
      ".proto\022\022tensorflow.serving\032,tensorflow_s"
      "erving/apis/classification.proto\032\'tensor"
      "flow_serving/apis/inference.proto\032%tenso"
      "rflow_serving/apis/predict.proto\032(tensor"
      "flow_serving/apis/regression.proto\032-tens"
      "orflow_serving/apis/session_service.prot"
      "o\032%tensorflow_serving/core/logging.proto"
      "\"\207\001\n\013ClassifyLog\022:\n\007request\030\001 \001(\0132).tens"
      "orflow.serving.ClassificationRequest\022<\n\010"
      "response\030\002 \001(\0132*.tensorflow.serving.Clas"
      "sificationResponse\"~\n\nRegressLog\0226\n\007requ"
      "est\030\001 \001(\0132%.tensorflow.serving.Regressio"
      "nRequest\0228\n\010response\030\002 \001(\0132&.tensorflow."
      "serving.RegressionResponse\"x\n\nPredictLog"
      "\0223\n\007request\030\001 \001(\0132\".tensorflow.serving.P"
      "redictRequest\0225\n\010response\030\002 \001(\0132#.tensor"
      "flow.serving.PredictResponse\"\215\001\n\021MultiIn"
      "ferenceLog\022:\n\007request\030\001 \001(\0132).tensorflow"
      ".serving.MultiInferenceRequest\022<\n\010respon"
      "se\030\002 \001(\0132*.tensorflow.serving.MultiInfer"
      "enceResponse\"\201\001\n\rSessionRunLog\0226\n\007reques"
      "t\030\001 \001(\0132%.tensorflow.serving.SessionRunR"
      "equest\0228\n\010response\030\002 \001(\0132&.tensorflow.se"
      "rving.SessionRunResponse\"\375\002\n\rPredictionL"
      "og\0225\n\014log_metadata\030\001 \001(\0132\037.tensorflow.se"
      "rving.LogMetadata\0227\n\014classify_log\030\002 \001(\0132"
      "\037.tensorflow.serving.ClassifyLogH\000\0225\n\013re"
      "gress_log\030\003 \001(\0132\036.tensorflow.serving.Reg"
      "ressLogH\000\0225\n\013predict_log\030\006 \001(\0132\036.tensorf"
      "low.serving.PredictLogH\000\022D\n\023multi_infere"
      "nce_log\030\004 \001(\0132%.tensorflow.serving.Multi"
      "InferenceLogH\000\022<\n\017session_run_log\030\005 \001(\0132"
      "!.tensorflow.serving.SessionRunLogH\000B\n\n\010"
      "log_typeB\003\370\001\001b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 1381);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/apis/prediction_log.proto", &protobuf_RegisterTypes);
  ::protobuf_tensorflow_5fserving_2fapis_2fclassification_2eproto::AddDescriptors();
  ::protobuf_tensorflow_5fserving_2fapis_2finference_2eproto::AddDescriptors();
  ::protobuf_tensorflow_5fserving_2fapis_2fpredict_2eproto::AddDescriptors();
  ::protobuf_tensorflow_5fserving_2fapis_2fregression_2eproto::AddDescriptors();
  ::protobuf_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto::AddDescriptors();
  ::protobuf_tensorflow_5fserving_2fcore_2flogging_2eproto::AddDescriptors();
}

void AddDescriptors() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at dynamic initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto
namespace tensorflow {
namespace serving {

// ===================================================================

void ClassifyLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_ClassifyLog_default_instance_._instance.get_mutable()->request_ = const_cast< ::tensorflow::serving::ClassificationRequest*>(
      ::tensorflow::serving::ClassificationRequest::internal_default_instance());
  ::tensorflow::serving::_ClassifyLog_default_instance_._instance.get_mutable()->response_ = const_cast< ::tensorflow::serving::ClassificationResponse*>(
      ::tensorflow::serving::ClassificationResponse::internal_default_instance());
}
void ClassifyLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::ClassificationRequest* request) {
  if (GetArenaNoVirtual() == NULL) {
    delete request_;
  }
  request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ClassifyLog.request)
}
void ClassifyLog::clear_request() {
  if (GetArenaNoVirtual() == NULL && request_ != NULL) {
    delete request_;
  }
  request_ = NULL;
}
void ClassifyLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::ClassificationResponse* response) {
  if (GetArenaNoVirtual() == NULL) {
    delete response_;
  }
  response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ClassifyLog.response)
}
void ClassifyLog::clear_response() {
  if (GetArenaNoVirtual() == NULL && response_ != NULL) {
    delete response_;
  }
  response_ = NULL;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ClassifyLog::kRequestFieldNumber;
const int ClassifyLog::kResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ClassifyLog::ClassifyLog()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_ClassifyLog.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ClassifyLog)
}
ClassifyLog::ClassifyLog(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_ClassifyLog.base);
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ClassifyLog)
}
ClassifyLog::ClassifyLog(const ClassifyLog& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_request()) {
    request_ = new ::tensorflow::serving::ClassificationRequest(*from.request_);
  } else {
    request_ = NULL;
  }
  if (from.has_response()) {
    response_ = new ::tensorflow::serving::ClassificationResponse(*from.response_);
  } else {
    response_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ClassifyLog)
}

void ClassifyLog::SharedCtor() {
  ::memset(&request_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&response_) -
      reinterpret_cast<char*>(&request_)) + sizeof(response_));
}

ClassifyLog::~ClassifyLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ClassifyLog)
  SharedDtor();
}

void ClassifyLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == NULL);
  if (this != internal_default_instance()) delete request_;
  if (this != internal_default_instance()) delete response_;
}

void ClassifyLog::ArenaDtor(void* object) {
  ClassifyLog* _this = reinterpret_cast< ClassifyLog* >(object);
  (void)_this;
}
void ClassifyLog::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ClassifyLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* ClassifyLog::descriptor() {
  ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const ClassifyLog& ClassifyLog::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_ClassifyLog.base);
  return *internal_default_instance();
}


void ClassifyLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ClassifyLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == NULL && request_ != NULL) {
    delete request_;
  }
  request_ = NULL;
  if (GetArenaNoVirtual() == NULL && response_ != NULL) {
    delete response_;
  }
  response_ = NULL;
  _internal_metadata_.Clear();
}

bool ClassifyLog::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ClassifyLog)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.ClassificationRequest request = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_request()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.ClassificationResponse response = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u /* 18 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_response()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ClassifyLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ClassifyLog)
  return false;
#undef DO_
}

void ClassifyLog::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ClassifyLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.ClassificationRequest request = 1;
  if (this->has_request()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_request(), output);
  }

  // .tensorflow.serving.ClassificationResponse response = 2;
  if (this->has_response()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->_internal_response(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ClassifyLog)
}

::google::protobuf::uint8* ClassifyLog::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ClassifyLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.ClassificationRequest request = 1;
  if (this->has_request()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_request(), deterministic, target);
  }

  // .tensorflow.serving.ClassificationResponse response = 2;
  if (this->has_response()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, this->_internal_response(), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ClassifyLog)
  return target;
}

size_t ClassifyLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ClassifyLog)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // .tensorflow.serving.ClassificationRequest request = 1;
  if (this->has_request()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *request_);
  }

  // .tensorflow.serving.ClassificationResponse response = 2;
  if (this->has_response()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *response_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void ClassifyLog::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ClassifyLog)
  GOOGLE_DCHECK_NE(&from, this);
  const ClassifyLog* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const ClassifyLog>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ClassifyLog)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ClassifyLog)
    MergeFrom(*source);
  }
}

void ClassifyLog::MergeFrom(const ClassifyLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ClassifyLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_request()) {
    mutable_request()->::tensorflow::serving::ClassificationRequest::MergeFrom(from.request());
  }
  if (from.has_response()) {
    mutable_response()->::tensorflow::serving::ClassificationResponse::MergeFrom(from.response());
  }
}

void ClassifyLog::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ClassifyLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ClassifyLog::CopyFrom(const ClassifyLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ClassifyLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ClassifyLog::IsInitialized() const {
  return true;
}

void ClassifyLog::Swap(ClassifyLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ClassifyLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void ClassifyLog::UnsafeArenaSwap(ClassifyLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ClassifyLog::InternalSwap(ClassifyLog* other) {
  using std::swap;
  swap(request_, other->request_);
  swap(response_, other->response_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata ClassifyLog::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void RegressLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_RegressLog_default_instance_._instance.get_mutable()->request_ = const_cast< ::tensorflow::serving::RegressionRequest*>(
      ::tensorflow::serving::RegressionRequest::internal_default_instance());
  ::tensorflow::serving::_RegressLog_default_instance_._instance.get_mutable()->response_ = const_cast< ::tensorflow::serving::RegressionResponse*>(
      ::tensorflow::serving::RegressionResponse::internal_default_instance());
}
void RegressLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::RegressionRequest* request) {
  if (GetArenaNoVirtual() == NULL) {
    delete request_;
  }
  request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.RegressLog.request)
}
void RegressLog::clear_request() {
  if (GetArenaNoVirtual() == NULL && request_ != NULL) {
    delete request_;
  }
  request_ = NULL;
}
void RegressLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::RegressionResponse* response) {
  if (GetArenaNoVirtual() == NULL) {
    delete response_;
  }
  response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.RegressLog.response)
}
void RegressLog::clear_response() {
  if (GetArenaNoVirtual() == NULL && response_ != NULL) {
    delete response_;
  }
  response_ = NULL;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RegressLog::kRequestFieldNumber;
const int RegressLog::kResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RegressLog::RegressLog()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_RegressLog.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.RegressLog)
}
RegressLog::RegressLog(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_RegressLog.base);
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.RegressLog)
}
RegressLog::RegressLog(const RegressLog& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_request()) {
    request_ = new ::tensorflow::serving::RegressionRequest(*from.request_);
  } else {
    request_ = NULL;
  }
  if (from.has_response()) {
    response_ = new ::tensorflow::serving::RegressionResponse(*from.response_);
  } else {
    response_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.RegressLog)
}

void RegressLog::SharedCtor() {
  ::memset(&request_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&response_) -
      reinterpret_cast<char*>(&request_)) + sizeof(response_));
}

RegressLog::~RegressLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.RegressLog)
  SharedDtor();
}

void RegressLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == NULL);
  if (this != internal_default_instance()) delete request_;
  if (this != internal_default_instance()) delete response_;
}

void RegressLog::ArenaDtor(void* object) {
  RegressLog* _this = reinterpret_cast< RegressLog* >(object);
  (void)_this;
}
void RegressLog::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void RegressLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* RegressLog::descriptor() {
  ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const RegressLog& RegressLog::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_RegressLog.base);
  return *internal_default_instance();
}


void RegressLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.RegressLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == NULL && request_ != NULL) {
    delete request_;
  }
  request_ = NULL;
  if (GetArenaNoVirtual() == NULL && response_ != NULL) {
    delete response_;
  }
  response_ = NULL;
  _internal_metadata_.Clear();
}

bool RegressLog::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.RegressLog)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.RegressionRequest request = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_request()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.RegressionResponse response = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u /* 18 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_response()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.RegressLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.RegressLog)
  return false;
#undef DO_
}

void RegressLog::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.RegressLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.RegressionRequest request = 1;
  if (this->has_request()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_request(), output);
  }

  // .tensorflow.serving.RegressionResponse response = 2;
  if (this->has_response()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->_internal_response(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.RegressLog)
}

::google::protobuf::uint8* RegressLog::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.RegressLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.RegressionRequest request = 1;
  if (this->has_request()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_request(), deterministic, target);
  }

  // .tensorflow.serving.RegressionResponse response = 2;
  if (this->has_response()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, this->_internal_response(), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.RegressLog)
  return target;
}

size_t RegressLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.RegressLog)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // .tensorflow.serving.RegressionRequest request = 1;
  if (this->has_request()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *request_);
  }

  // .tensorflow.serving.RegressionResponse response = 2;
  if (this->has_response()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *response_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void RegressLog::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.RegressLog)
  GOOGLE_DCHECK_NE(&from, this);
  const RegressLog* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const RegressLog>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.RegressLog)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.RegressLog)
    MergeFrom(*source);
  }
}

void RegressLog::MergeFrom(const RegressLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.RegressLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_request()) {
    mutable_request()->::tensorflow::serving::RegressionRequest::MergeFrom(from.request());
  }
  if (from.has_response()) {
    mutable_response()->::tensorflow::serving::RegressionResponse::MergeFrom(from.response());
  }
}

void RegressLog::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.RegressLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RegressLog::CopyFrom(const RegressLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.RegressLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RegressLog::IsInitialized() const {
  return true;
}

void RegressLog::Swap(RegressLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    RegressLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void RegressLog::UnsafeArenaSwap(RegressLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void RegressLog::InternalSwap(RegressLog* other) {
  using std::swap;
  swap(request_, other->request_);
  swap(response_, other->response_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata RegressLog::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void PredictLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_PredictLog_default_instance_._instance.get_mutable()->request_ = const_cast< ::tensorflow::serving::PredictRequest*>(
      ::tensorflow::serving::PredictRequest::internal_default_instance());
  ::tensorflow::serving::_PredictLog_default_instance_._instance.get_mutable()->response_ = const_cast< ::tensorflow::serving::PredictResponse*>(
      ::tensorflow::serving::PredictResponse::internal_default_instance());
}
void PredictLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::PredictRequest* request) {
  if (GetArenaNoVirtual() == NULL) {
    delete request_;
  }
  request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictLog.request)
}
void PredictLog::clear_request() {
  if (GetArenaNoVirtual() == NULL && request_ != NULL) {
    delete request_;
  }
  request_ = NULL;
}
void PredictLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::PredictResponse* response) {
  if (GetArenaNoVirtual() == NULL) {
    delete response_;
  }
  response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictLog.response)
}
void PredictLog::clear_response() {
  if (GetArenaNoVirtual() == NULL && response_ != NULL) {
    delete response_;
  }
  response_ = NULL;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int PredictLog::kRequestFieldNumber;
const int PredictLog::kResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

PredictLog::PredictLog()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_PredictLog.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.PredictLog)
}
PredictLog::PredictLog(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_PredictLog.base);
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictLog)
}
PredictLog::PredictLog(const PredictLog& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_request()) {
    request_ = new ::tensorflow::serving::PredictRequest(*from.request_);
  } else {
    request_ = NULL;
  }
  if (from.has_response()) {
    response_ = new ::tensorflow::serving::PredictResponse(*from.response_);
  } else {
    response_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictLog)
}

void PredictLog::SharedCtor() {
  ::memset(&request_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&response_) -
      reinterpret_cast<char*>(&request_)) + sizeof(response_));
}

PredictLog::~PredictLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictLog)
  SharedDtor();
}

void PredictLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == NULL);
  if (this != internal_default_instance()) delete request_;
  if (this != internal_default_instance()) delete response_;
}

void PredictLog::ArenaDtor(void* object) {
  PredictLog* _this = reinterpret_cast< PredictLog* >(object);
  (void)_this;
}
void PredictLog::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void PredictLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* PredictLog::descriptor() {
  ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const PredictLog& PredictLog::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_PredictLog.base);
  return *internal_default_instance();
}


void PredictLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == NULL && request_ != NULL) {
    delete request_;
  }
  request_ = NULL;
  if (GetArenaNoVirtual() == NULL && response_ != NULL) {
    delete response_;
  }
  response_ = NULL;
  _internal_metadata_.Clear();
}

bool PredictLog::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.PredictLog)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.PredictRequest request = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_request()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.PredictResponse response = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u /* 18 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_response()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.PredictLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.PredictLog)
  return false;
#undef DO_
}

void PredictLog::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.PredictLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.PredictRequest request = 1;
  if (this->has_request()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_request(), output);
  }

  // .tensorflow.serving.PredictResponse response = 2;
  if (this->has_response()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->_internal_response(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.PredictLog)
}

::google::protobuf::uint8* PredictLog::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.PredictRequest request = 1;
  if (this->has_request()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_request(), deterministic, target);
  }

  // .tensorflow.serving.PredictResponse response = 2;
  if (this->has_response()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, this->_internal_response(), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictLog)
  return target;
}

size_t PredictLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictLog)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // .tensorflow.serving.PredictRequest request = 1;
  if (this->has_request()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *request_);
  }

  // .tensorflow.serving.PredictResponse response = 2;
  if (this->has_response()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *response_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void PredictLog::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.PredictLog)
  GOOGLE_DCHECK_NE(&from, this);
  const PredictLog* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const PredictLog>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.PredictLog)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.PredictLog)
    MergeFrom(*source);
  }
}

void PredictLog::MergeFrom(const PredictLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_request()) {
    mutable_request()->::tensorflow::serving::PredictRequest::MergeFrom(from.request());
  }
  if (from.has_response()) {
    mutable_response()->::tensorflow::serving::PredictResponse::MergeFrom(from.response());
  }
}

void PredictLog::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.PredictLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void PredictLog::CopyFrom(const PredictLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictLog::IsInitialized() const {
  return true;
}

void PredictLog::Swap(PredictLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    PredictLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void PredictLog::UnsafeArenaSwap(PredictLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void PredictLog::InternalSwap(PredictLog* other) {
  using std::swap;
  swap(request_, other->request_);
  swap(response_, other->response_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata PredictLog::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void MultiInferenceLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_MultiInferenceLog_default_instance_._instance.get_mutable()->request_ = const_cast< ::tensorflow::serving::MultiInferenceRequest*>(
      ::tensorflow::serving::MultiInferenceRequest::internal_default_instance());
  ::tensorflow::serving::_MultiInferenceLog_default_instance_._instance.get_mutable()->response_ = const_cast< ::tensorflow::serving::MultiInferenceResponse*>(
      ::tensorflow::serving::MultiInferenceResponse::internal_default_instance());
}
void MultiInferenceLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::MultiInferenceRequest* request) {
  if (GetArenaNoVirtual() == NULL) {
    delete request_;
  }
  request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.MultiInferenceLog.request)
}
void MultiInferenceLog::clear_request() {
  if (GetArenaNoVirtual() == NULL && request_ != NULL) {
    delete request_;
  }
  request_ = NULL;
}
void MultiInferenceLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::MultiInferenceResponse* response) {
  if (GetArenaNoVirtual() == NULL) {
    delete response_;
  }
  response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.MultiInferenceLog.response)
}
void MultiInferenceLog::clear_response() {
  if (GetArenaNoVirtual() == NULL && response_ != NULL) {
    delete response_;
  }
  response_ = NULL;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int MultiInferenceLog::kRequestFieldNumber;
const int MultiInferenceLog::kResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

MultiInferenceLog::MultiInferenceLog()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_MultiInferenceLog.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.MultiInferenceLog)
}
MultiInferenceLog::MultiInferenceLog(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_MultiInferenceLog.base);
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.MultiInferenceLog)
}
MultiInferenceLog::MultiInferenceLog(const MultiInferenceLog& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_request()) {
    request_ = new ::tensorflow::serving::MultiInferenceRequest(*from.request_);
  } else {
    request_ = NULL;
  }
  if (from.has_response()) {
    response_ = new ::tensorflow::serving::MultiInferenceResponse(*from.response_);
  } else {
    response_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.MultiInferenceLog)
}

void MultiInferenceLog::SharedCtor() {
  ::memset(&request_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&response_) -
      reinterpret_cast<char*>(&request_)) + sizeof(response_));
}

MultiInferenceLog::~MultiInferenceLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.MultiInferenceLog)
  SharedDtor();
}

void MultiInferenceLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == NULL);
  if (this != internal_default_instance()) delete request_;
  if (this != internal_default_instance()) delete response_;
}

void MultiInferenceLog::ArenaDtor(void* object) {
  MultiInferenceLog* _this = reinterpret_cast< MultiInferenceLog* >(object);
  (void)_this;
}
void MultiInferenceLog::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void MultiInferenceLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* MultiInferenceLog::descriptor() {
  ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const MultiInferenceLog& MultiInferenceLog::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_MultiInferenceLog.base);
  return *internal_default_instance();
}


void MultiInferenceLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.MultiInferenceLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == NULL && request_ != NULL) {
    delete request_;
  }
  request_ = NULL;
  if (GetArenaNoVirtual() == NULL && response_ != NULL) {
    delete response_;
  }
  response_ = NULL;
  _internal_metadata_.Clear();
}

bool MultiInferenceLog::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.MultiInferenceLog)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.MultiInferenceRequest request = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_request()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.MultiInferenceResponse response = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u /* 18 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_response()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.MultiInferenceLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.MultiInferenceLog)
  return false;
#undef DO_
}

void MultiInferenceLog::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.MultiInferenceLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.MultiInferenceRequest request = 1;
  if (this->has_request()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_request(), output);
  }

  // .tensorflow.serving.MultiInferenceResponse response = 2;
  if (this->has_response()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->_internal_response(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.MultiInferenceLog)
}

::google::protobuf::uint8* MultiInferenceLog::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.MultiInferenceLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.MultiInferenceRequest request = 1;
  if (this->has_request()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_request(), deterministic, target);
  }

  // .tensorflow.serving.MultiInferenceResponse response = 2;
  if (this->has_response()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, this->_internal_response(), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.MultiInferenceLog)
  return target;
}

size_t MultiInferenceLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.MultiInferenceLog)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // .tensorflow.serving.MultiInferenceRequest request = 1;
  if (this->has_request()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *request_);
  }

  // .tensorflow.serving.MultiInferenceResponse response = 2;
  if (this->has_response()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *response_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void MultiInferenceLog::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.MultiInferenceLog)
  GOOGLE_DCHECK_NE(&from, this);
  const MultiInferenceLog* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const MultiInferenceLog>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.MultiInferenceLog)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.MultiInferenceLog)
    MergeFrom(*source);
  }
}

void MultiInferenceLog::MergeFrom(const MultiInferenceLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.MultiInferenceLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_request()) {
    mutable_request()->::tensorflow::serving::MultiInferenceRequest::MergeFrom(from.request());
  }
  if (from.has_response()) {
    mutable_response()->::tensorflow::serving::MultiInferenceResponse::MergeFrom(from.response());
  }
}

void MultiInferenceLog::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.MultiInferenceLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void MultiInferenceLog::CopyFrom(const MultiInferenceLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.MultiInferenceLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MultiInferenceLog::IsInitialized() const {
  return true;
}

void MultiInferenceLog::Swap(MultiInferenceLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    MultiInferenceLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void MultiInferenceLog::UnsafeArenaSwap(MultiInferenceLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void MultiInferenceLog::InternalSwap(MultiInferenceLog* other) {
  using std::swap;
  swap(request_, other->request_);
  swap(response_, other->response_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata MultiInferenceLog::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void SessionRunLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_SessionRunLog_default_instance_._instance.get_mutable()->request_ = const_cast< ::tensorflow::serving::SessionRunRequest*>(
      ::tensorflow::serving::SessionRunRequest::internal_default_instance());
  ::tensorflow::serving::_SessionRunLog_default_instance_._instance.get_mutable()->response_ = const_cast< ::tensorflow::serving::SessionRunResponse*>(
      ::tensorflow::serving::SessionRunResponse::internal_default_instance());
}
void SessionRunLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::SessionRunRequest* request) {
  if (GetArenaNoVirtual() == NULL) {
    delete request_;
  }
  request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunLog.request)
}
void SessionRunLog::clear_request() {
  if (GetArenaNoVirtual() == NULL && request_ != NULL) {
    delete request_;
  }
  request_ = NULL;
}
void SessionRunLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::SessionRunResponse* response) {
  if (GetArenaNoVirtual() == NULL) {
    delete response_;
  }
  response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunLog.response)
}
void SessionRunLog::clear_response() {
  if (GetArenaNoVirtual() == NULL && response_ != NULL) {
    delete response_;
  }
  response_ = NULL;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SessionRunLog::kRequestFieldNumber;
const int SessionRunLog::kResponseFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SessionRunLog::SessionRunLog()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_SessionRunLog.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.SessionRunLog)
}
SessionRunLog::SessionRunLog(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_SessionRunLog.base);
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.SessionRunLog)
}
SessionRunLog::SessionRunLog(const SessionRunLog& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_request()) {
    request_ = new ::tensorflow::serving::SessionRunRequest(*from.request_);
  } else {
    request_ = NULL;
  }
  if (from.has_response()) {
    response_ = new ::tensorflow::serving::SessionRunResponse(*from.response_);
  } else {
    response_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.SessionRunLog)
}

void SessionRunLog::SharedCtor() {
  ::memset(&request_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&response_) -
      reinterpret_cast<char*>(&request_)) + sizeof(response_));
}

SessionRunLog::~SessionRunLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.SessionRunLog)
  SharedDtor();
}

void SessionRunLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == NULL);
  if (this != internal_default_instance()) delete request_;
  if (this != internal_default_instance()) delete response_;
}

void SessionRunLog::ArenaDtor(void* object) {
  SessionRunLog* _this = reinterpret_cast< SessionRunLog* >(object);
  (void)_this;
}
void SessionRunLog::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void SessionRunLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* SessionRunLog::descriptor() {
  ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const SessionRunLog& SessionRunLog::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_SessionRunLog.base);
  return *internal_default_instance();
}


void SessionRunLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.SessionRunLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == NULL && request_ != NULL) {
    delete request_;
  }
  request_ = NULL;
  if (GetArenaNoVirtual() == NULL && response_ != NULL) {
    delete response_;
  }
  response_ = NULL;
  _internal_metadata_.Clear();
}

bool SessionRunLog::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.SessionRunLog)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.SessionRunRequest request = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_request()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.SessionRunResponse response = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u /* 18 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_response()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.SessionRunLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.SessionRunLog)
  return false;
#undef DO_
}

void SessionRunLog::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.SessionRunLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.SessionRunRequest request = 1;
  if (this->has_request()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_request(), output);
  }

  // .tensorflow.serving.SessionRunResponse response = 2;
  if (this->has_response()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->_internal_response(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.SessionRunLog)
}

::google::protobuf::uint8* SessionRunLog::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.SessionRunLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.SessionRunRequest request = 1;
  if (this->has_request()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_request(), deterministic, target);
  }

  // .tensorflow.serving.SessionRunResponse response = 2;
  if (this->has_response()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, this->_internal_response(), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.SessionRunLog)
  return target;
}

size_t SessionRunLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.SessionRunLog)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // .tensorflow.serving.SessionRunRequest request = 1;
  if (this->has_request()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *request_);
  }

  // .tensorflow.serving.SessionRunResponse response = 2;
  if (this->has_response()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *response_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void SessionRunLog::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.SessionRunLog)
  GOOGLE_DCHECK_NE(&from, this);
  const SessionRunLog* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const SessionRunLog>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.SessionRunLog)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.SessionRunLog)
    MergeFrom(*source);
  }
}

void SessionRunLog::MergeFrom(const SessionRunLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.SessionRunLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_request()) {
    mutable_request()->::tensorflow::serving::SessionRunRequest::MergeFrom(from.request());
  }
  if (from.has_response()) {
    mutable_response()->::tensorflow::serving::SessionRunResponse::MergeFrom(from.response());
  }
}

void SessionRunLog::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.SessionRunLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SessionRunLog::CopyFrom(const SessionRunLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.SessionRunLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SessionRunLog::IsInitialized() const {
  return true;
}

void SessionRunLog::Swap(SessionRunLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    SessionRunLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void SessionRunLog::UnsafeArenaSwap(SessionRunLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void SessionRunLog::InternalSwap(SessionRunLog* other) {
  using std::swap;
  swap(request_, other->request_);
  swap(response_, other->response_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata SessionRunLog::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void PredictionLog::InitAsDefaultInstance() {
  ::tensorflow::serving::_PredictionLog_default_instance_._instance.get_mutable()->log_metadata_ = const_cast< ::tensorflow::serving::LogMetadata*>(
      ::tensorflow::serving::LogMetadata::internal_default_instance());
  ::tensorflow::serving::_PredictionLog_default_instance_.classify_log_ = const_cast< ::tensorflow::serving::ClassifyLog*>(
      ::tensorflow::serving::ClassifyLog::internal_default_instance());
  ::tensorflow::serving::_PredictionLog_default_instance_.regress_log_ = const_cast< ::tensorflow::serving::RegressLog*>(
      ::tensorflow::serving::RegressLog::internal_default_instance());
  ::tensorflow::serving::_PredictionLog_default_instance_.predict_log_ = const_cast< ::tensorflow::serving::PredictLog*>(
      ::tensorflow::serving::PredictLog::internal_default_instance());
  ::tensorflow::serving::_PredictionLog_default_instance_.multi_inference_log_ = const_cast< ::tensorflow::serving::MultiInferenceLog*>(
      ::tensorflow::serving::MultiInferenceLog::internal_default_instance());
  ::tensorflow::serving::_PredictionLog_default_instance_.session_run_log_ = const_cast< ::tensorflow::serving::SessionRunLog*>(
      ::tensorflow::serving::SessionRunLog::internal_default_instance());
}
void PredictionLog::unsafe_arena_set_allocated_log_metadata(
    ::tensorflow::serving::LogMetadata* log_metadata) {
  if (GetArenaNoVirtual() == NULL) {
    delete log_metadata_;
  }
  log_metadata_ = log_metadata;
  if (log_metadata) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.log_metadata)
}
void PredictionLog::clear_log_metadata() {
  if (GetArenaNoVirtual() == NULL && log_metadata_ != NULL) {
    delete log_metadata_;
  }
  log_metadata_ = NULL;
}
void PredictionLog::set_allocated_classify_log(::tensorflow::serving::ClassifyLog* classify_log) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  clear_log_type();
  if (classify_log) {
    ::google::protobuf::Arena* submessage_arena =
      ::google::protobuf::Arena::GetArena(classify_log);
    if (message_arena != submessage_arena) {
      classify_log = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, classify_log, submessage_arena);
    }
    set_has_classify_log();
    log_type_.classify_log_ = classify_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.classify_log)
}
void PredictionLog::set_allocated_regress_log(::tensorflow::serving::RegressLog* regress_log) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  clear_log_type();
  if (regress_log) {
    ::google::protobuf::Arena* submessage_arena =
      ::google::protobuf::Arena::GetArena(regress_log);
    if (message_arena != submessage_arena) {
      regress_log = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, regress_log, submessage_arena);
    }
    set_has_regress_log();
    log_type_.regress_log_ = regress_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.regress_log)
}
void PredictionLog::set_allocated_predict_log(::tensorflow::serving::PredictLog* predict_log) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  clear_log_type();
  if (predict_log) {
    ::google::protobuf::Arena* submessage_arena =
      ::google::protobuf::Arena::GetArena(predict_log);
    if (message_arena != submessage_arena) {
      predict_log = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, predict_log, submessage_arena);
    }
    set_has_predict_log();
    log_type_.predict_log_ = predict_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.predict_log)
}
void PredictionLog::set_allocated_multi_inference_log(::tensorflow::serving::MultiInferenceLog* multi_inference_log) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  clear_log_type();
  if (multi_inference_log) {
    ::google::protobuf::Arena* submessage_arena =
      ::google::protobuf::Arena::GetArena(multi_inference_log);
    if (message_arena != submessage_arena) {
      multi_inference_log = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, multi_inference_log, submessage_arena);
    }
    set_has_multi_inference_log();
    log_type_.multi_inference_log_ = multi_inference_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.multi_inference_log)
}
void PredictionLog::set_allocated_session_run_log(::tensorflow::serving::SessionRunLog* session_run_log) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  clear_log_type();
  if (session_run_log) {
    ::google::protobuf::Arena* submessage_arena =
      ::google::protobuf::Arena::GetArena(session_run_log);
    if (message_arena != submessage_arena) {
      session_run_log = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, session_run_log, submessage_arena);
    }
    set_has_session_run_log();
    log_type_.session_run_log_ = session_run_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.session_run_log)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int PredictionLog::kLogMetadataFieldNumber;
const int PredictionLog::kClassifyLogFieldNumber;
const int PredictionLog::kRegressLogFieldNumber;
const int PredictionLog::kPredictLogFieldNumber;
const int PredictionLog::kMultiInferenceLogFieldNumber;
const int PredictionLog::kSessionRunLogFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

PredictionLog::PredictionLog()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_PredictionLog.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.PredictionLog)
}
PredictionLog::PredictionLog(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_PredictionLog.base);
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictionLog)
}
PredictionLog::PredictionLog(const PredictionLog& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_log_metadata()) {
    log_metadata_ = new ::tensorflow::serving::LogMetadata(*from.log_metadata_);
  } else {
    log_metadata_ = NULL;
  }
  clear_has_log_type();
  switch (from.log_type_case()) {
    case kClassifyLog: {
      mutable_classify_log()->::tensorflow::serving::ClassifyLog::MergeFrom(from.classify_log());
      break;
    }
    case kRegressLog: {
      mutable_regress_log()->::tensorflow::serving::RegressLog::MergeFrom(from.regress_log());
      break;
    }
    case kPredictLog: {
      mutable_predict_log()->::tensorflow::serving::PredictLog::MergeFrom(from.predict_log());
      break;
    }
    case kMultiInferenceLog: {
      mutable_multi_inference_log()->::tensorflow::serving::MultiInferenceLog::MergeFrom(from.multi_inference_log());
      break;
    }
    case kSessionRunLog: {
      mutable_session_run_log()->::tensorflow::serving::SessionRunLog::MergeFrom(from.session_run_log());
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictionLog)
}

void PredictionLog::SharedCtor() {
  log_metadata_ = NULL;
  clear_has_log_type();
}

PredictionLog::~PredictionLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictionLog)
  SharedDtor();
}

void PredictionLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == NULL);
  if (this != internal_default_instance()) delete log_metadata_;
  if (has_log_type()) {
    clear_log_type();
  }
}

void PredictionLog::ArenaDtor(void* object) {
  PredictionLog* _this = reinterpret_cast< PredictionLog* >(object);
  (void)_this;
}
void PredictionLog::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void PredictionLog::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* PredictionLog::descriptor() {
  ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const PredictionLog& PredictionLog::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::scc_info_PredictionLog.base);
  return *internal_default_instance();
}


void PredictionLog::clear_log_type() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.serving.PredictionLog)
  switch (log_type_case()) {
    case kClassifyLog: {
      if (GetArenaNoVirtual() == NULL) {
        delete log_type_.classify_log_;
      }
      break;
    }
    case kRegressLog: {
      if (GetArenaNoVirtual() == NULL) {
        delete log_type_.regress_log_;
      }
      break;
    }
    case kPredictLog: {
      if (GetArenaNoVirtual() == NULL) {
        delete log_type_.predict_log_;
      }
      break;
    }
    case kMultiInferenceLog: {
      if (GetArenaNoVirtual() == NULL) {
        delete log_type_.multi_inference_log_;
      }
      break;
    }
    case kSessionRunLog: {
      if (GetArenaNoVirtual() == NULL) {
        delete log_type_.session_run_log_;
      }
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = LOG_TYPE_NOT_SET;
}


void PredictionLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictionLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == NULL && log_metadata_ != NULL) {
    delete log_metadata_;
  }
  log_metadata_ = NULL;
  clear_log_type();
  _internal_metadata_.Clear();
}

bool PredictionLog::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.PredictionLog)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.LogMetadata log_metadata = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_log_metadata()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.ClassifyLog classify_log = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(18u /* 18 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_classify_log()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.RegressLog regress_log = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(26u /* 26 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_regress_log()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
      case 4: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(34u /* 34 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_multi_inference_log()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.SessionRunLog session_run_log = 5;
      case 5: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(42u /* 42 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_session_run_log()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.PredictLog predict_log = 6;
      case 6: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(50u /* 50 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_predict_log()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.PredictionLog)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.PredictionLog)
  return false;
#undef DO_
}

void PredictionLog::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.PredictionLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.LogMetadata log_metadata = 1;
  if (this->has_log_metadata()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_log_metadata(), output);
  }

  // .tensorflow.serving.ClassifyLog classify_log = 2;
  if (has_classify_log()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->_internal_classify_log(), output);
  }

  // .tensorflow.serving.RegressLog regress_log = 3;
  if (has_regress_log()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, this->_internal_regress_log(), output);
  }

  // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
  if (has_multi_inference_log()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, this->_internal_multi_inference_log(), output);
  }

  // .tensorflow.serving.SessionRunLog session_run_log = 5;
  if (has_session_run_log()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      5, this->_internal_session_run_log(), output);
  }

  // .tensorflow.serving.PredictLog predict_log = 6;
  if (has_predict_log()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      6, this->_internal_predict_log(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.PredictionLog)
}

::google::protobuf::uint8* PredictionLog::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictionLog)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.LogMetadata log_metadata = 1;
  if (this->has_log_metadata()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_log_metadata(), deterministic, target);
  }

  // .tensorflow.serving.ClassifyLog classify_log = 2;
  if (has_classify_log()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        2, this->_internal_classify_log(), deterministic, target);
  }

  // .tensorflow.serving.RegressLog regress_log = 3;
  if (has_regress_log()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        3, this->_internal_regress_log(), deterministic, target);
  }

  // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
  if (has_multi_inference_log()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        4, this->_internal_multi_inference_log(), deterministic, target);
  }

  // .tensorflow.serving.SessionRunLog session_run_log = 5;
  if (has_session_run_log()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        5, this->_internal_session_run_log(), deterministic, target);
  }

  // .tensorflow.serving.PredictLog predict_log = 6;
  if (has_predict_log()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        6, this->_internal_predict_log(), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictionLog)
  return target;
}

size_t PredictionLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictionLog)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // .tensorflow.serving.LogMetadata log_metadata = 1;
  if (this->has_log_metadata()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *log_metadata_);
  }

  switch (log_type_case()) {
    // .tensorflow.serving.ClassifyLog classify_log = 2;
    case kClassifyLog: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSize(
          *log_type_.classify_log_);
      break;
    }
    // .tensorflow.serving.RegressLog regress_log = 3;
    case kRegressLog: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSize(
          *log_type_.regress_log_);
      break;
    }
    // .tensorflow.serving.PredictLog predict_log = 6;
    case kPredictLog: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSize(
          *log_type_.predict_log_);
      break;
    }
    // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
    case kMultiInferenceLog: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSize(
          *log_type_.multi_inference_log_);
      break;
    }
    // .tensorflow.serving.SessionRunLog session_run_log = 5;
    case kSessionRunLog: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSize(
          *log_type_.session_run_log_);
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void PredictionLog::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.PredictionLog)
  GOOGLE_DCHECK_NE(&from, this);
  const PredictionLog* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const PredictionLog>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.PredictionLog)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.PredictionLog)
    MergeFrom(*source);
  }
}

void PredictionLog::MergeFrom(const PredictionLog& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictionLog)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_log_metadata()) {
    mutable_log_metadata()->::tensorflow::serving::LogMetadata::MergeFrom(from.log_metadata());
  }
  switch (from.log_type_case()) {
    case kClassifyLog: {
      mutable_classify_log()->::tensorflow::serving::ClassifyLog::MergeFrom(from.classify_log());
      break;
    }
    case kRegressLog: {
      mutable_regress_log()->::tensorflow::serving::RegressLog::MergeFrom(from.regress_log());
      break;
    }
    case kPredictLog: {
      mutable_predict_log()->::tensorflow::serving::PredictLog::MergeFrom(from.predict_log());
      break;
    }
    case kMultiInferenceLog: {
      mutable_multi_inference_log()->::tensorflow::serving::MultiInferenceLog::MergeFrom(from.multi_inference_log());
      break;
    }
    case kSessionRunLog: {
      mutable_session_run_log()->::tensorflow::serving::SessionRunLog::MergeFrom(from.session_run_log());
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
}

void PredictionLog::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.PredictionLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void PredictionLog::CopyFrom(const PredictionLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictionLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictionLog::IsInitialized() const {
  return true;
}

void PredictionLog::Swap(PredictionLog* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    PredictionLog* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void PredictionLog::UnsafeArenaSwap(PredictionLog* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void PredictionLog::InternalSwap(PredictionLog* other) {
  using std::swap;
  swap(log_metadata_, other->log_metadata_);
  swap(log_type_, other->log_type_);
  swap(_oneof_case_[0], other->_oneof_case_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata PredictionLog::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::file_level_metadata[kIndexInFileMessages];
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow
namespace google {
namespace protobuf {
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::ClassifyLog* Arena::CreateMaybeMessage< ::tensorflow::serving::ClassifyLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::ClassifyLog >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::RegressLog* Arena::CreateMaybeMessage< ::tensorflow::serving::RegressLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::RegressLog >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::PredictLog* Arena::CreateMaybeMessage< ::tensorflow::serving::PredictLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictLog >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::MultiInferenceLog* Arena::CreateMaybeMessage< ::tensorflow::serving::MultiInferenceLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::MultiInferenceLog >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::SessionRunLog* Arena::CreateMaybeMessage< ::tensorflow::serving::SessionRunLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::SessionRunLog >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::PredictionLog* Arena::CreateMaybeMessage< ::tensorflow::serving::PredictionLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictionLog >(arena);
}
}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)
