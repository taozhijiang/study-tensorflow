// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/get_model_status.proto

#include "tensorflow_serving/apis/get_model_status.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// This is a temporary google only hack
#ifdef GOOGLE_PROTOBUF_ENFORCE_UNIQUENESS
#include "third_party/protobuf/version.h"
#endif
// @@protoc_insertion_point(includes)

namespace protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto ::google::protobuf::internal::SCCInfo<1> scc_info_ModelVersionStatus;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto
namespace protobuf_tensorflow_5fserving_2fapis_2fmodel_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2fapis_2fmodel_2eproto ::google::protobuf::internal::SCCInfo<1> scc_info_ModelSpec;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2fmodel_2eproto
namespace protobuf_tensorflow_5fserving_2futil_2fstatus_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_tensorflow_5fserving_2futil_2fstatus_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_StatusProto;
}  // namespace protobuf_tensorflow_5fserving_2futil_2fstatus_2eproto
namespace tensorflow {
namespace serving {
class GetModelStatusRequestDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<GetModelStatusRequest>
      _instance;
} _GetModelStatusRequest_default_instance_;
class ModelVersionStatusDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<ModelVersionStatus>
      _instance;
} _ModelVersionStatus_default_instance_;
class GetModelStatusResponseDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<GetModelStatusResponse>
      _instance;
} _GetModelStatusResponse_default_instance_;
}  // namespace serving
}  // namespace tensorflow
namespace protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto {
static void InitDefaultsGetModelStatusRequest() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_GetModelStatusRequest_default_instance_;
    new (ptr) ::tensorflow::serving::GetModelStatusRequest();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::GetModelStatusRequest::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<1> scc_info_GetModelStatusRequest =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 1, InitDefaultsGetModelStatusRequest}, {
      &protobuf_tensorflow_5fserving_2fapis_2fmodel_2eproto::scc_info_ModelSpec.base,}};

static void InitDefaultsModelVersionStatus() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_ModelVersionStatus_default_instance_;
    new (ptr) ::tensorflow::serving::ModelVersionStatus();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::ModelVersionStatus::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<1> scc_info_ModelVersionStatus =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 1, InitDefaultsModelVersionStatus}, {
      &protobuf_tensorflow_5fserving_2futil_2fstatus_2eproto::scc_info_StatusProto.base,}};

static void InitDefaultsGetModelStatusResponse() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::tensorflow::serving::_GetModelStatusResponse_default_instance_;
    new (ptr) ::tensorflow::serving::GetModelStatusResponse();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::tensorflow::serving::GetModelStatusResponse::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<1> scc_info_GetModelStatusResponse =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 1, InitDefaultsGetModelStatusResponse}, {
      &protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::scc_info_ModelVersionStatus.base,}};

void InitDefaults() {
  ::google::protobuf::internal::InitSCC(&scc_info_GetModelStatusRequest.base);
  ::google::protobuf::internal::InitSCC(&scc_info_ModelVersionStatus.base);
  ::google::protobuf::internal::InitSCC(&scc_info_GetModelStatusResponse.base);
}

::google::protobuf::Metadata file_level_metadata[3];
const ::google::protobuf::EnumDescriptor* file_level_enum_descriptors[1];

const ::google::protobuf::uint32 TableStruct::offsets[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::GetModelStatusRequest, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::GetModelStatusRequest, model_spec_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::ModelVersionStatus, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::ModelVersionStatus, version_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::ModelVersionStatus, state_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::ModelVersionStatus, status_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::GetModelStatusResponse, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::tensorflow::serving::GetModelStatusResponse, model_version_status_),
};
static const ::google::protobuf::internal::MigrationSchema schemas[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, sizeof(::tensorflow::serving::GetModelStatusRequest)},
  { 6, -1, sizeof(::tensorflow::serving::ModelVersionStatus)},
  { 14, -1, sizeof(::tensorflow::serving::GetModelStatusResponse)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_GetModelStatusRequest_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_ModelVersionStatus_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::tensorflow::serving::_GetModelStatusResponse_default_instance_),
};

void protobuf_AssignDescriptors() {
  AddDescriptors();
  AssignDescriptors(
      "tensorflow_serving/apis/get_model_status.proto", schemas, file_default_instances, TableStruct::offsets,
      file_level_metadata, file_level_enum_descriptors, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_PROTOBUF_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 3);
}

void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
      "\n.tensorflow_serving/apis/get_model_stat"
      "us.proto\022\022tensorflow.serving\032#tensorflow"
      "_serving/apis/model.proto\032$tensorflow_se"
      "rving/util/status.proto\"J\n\025GetModelStatu"
      "sRequest\0221\n\nmodel_spec\030\001 \001(\0132\035.tensorflo"
      "w.serving.ModelSpec\"\350\001\n\022ModelVersionStat"
      "us\022\017\n\007version\030\001 \001(\003\022;\n\005state\030\002 \001(\0162,.ten"
      "sorflow.serving.ModelVersionStatus.State"
      "\022/\n\006status\030\003 \001(\0132\037.tensorflow.serving.St"
      "atusProto\"S\n\005State\022\013\n\007UNKNOWN\020\000\022\t\n\005START"
      "\020\n\022\013\n\007LOADING\020\024\022\r\n\tAVAILABLE\020\036\022\r\n\tUNLOAD"
      "ING\020(\022\007\n\003END\0202\"t\n\026GetModelStatusResponse"
      "\022Z\n\024model_version_status\030\001 \003(\0132&.tensorf"
      "low.serving.ModelVersionStatusR\024model_ve"
      "rsion_statusB\003\370\001\001b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 585);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/apis/get_model_status.proto", &protobuf_RegisterTypes);
  ::protobuf_tensorflow_5fserving_2fapis_2fmodel_2eproto::AddDescriptors();
  ::protobuf_tensorflow_5fserving_2futil_2fstatus_2eproto::AddDescriptors();
}

void AddDescriptors() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at dynamic initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;
}  // namespace protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto
namespace tensorflow {
namespace serving {
const ::google::protobuf::EnumDescriptor* ModelVersionStatus_State_descriptor() {
  protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::file_level_enum_descriptors[0];
}
bool ModelVersionStatus_State_IsValid(int value) {
  switch (value) {
    case 0:
    case 10:
    case 20:
    case 30:
    case 40:
    case 50:
      return true;
    default:
      return false;
  }
}

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const ModelVersionStatus_State ModelVersionStatus::UNKNOWN;
const ModelVersionStatus_State ModelVersionStatus::START;
const ModelVersionStatus_State ModelVersionStatus::LOADING;
const ModelVersionStatus_State ModelVersionStatus::AVAILABLE;
const ModelVersionStatus_State ModelVersionStatus::UNLOADING;
const ModelVersionStatus_State ModelVersionStatus::END;
const ModelVersionStatus_State ModelVersionStatus::State_MIN;
const ModelVersionStatus_State ModelVersionStatus::State_MAX;
const int ModelVersionStatus::State_ARRAYSIZE;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

// ===================================================================

void GetModelStatusRequest::InitAsDefaultInstance() {
  ::tensorflow::serving::_GetModelStatusRequest_default_instance_._instance.get_mutable()->model_spec_ = const_cast< ::tensorflow::serving::ModelSpec*>(
      ::tensorflow::serving::ModelSpec::internal_default_instance());
}
void GetModelStatusRequest::unsafe_arena_set_allocated_model_spec(
    ::tensorflow::serving::ModelSpec* model_spec) {
  if (GetArenaNoVirtual() == NULL) {
    delete model_spec_;
  }
  model_spec_ = model_spec;
  if (model_spec) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.GetModelStatusRequest.model_spec)
}
void GetModelStatusRequest::clear_model_spec() {
  if (GetArenaNoVirtual() == NULL && model_spec_ != NULL) {
    delete model_spec_;
  }
  model_spec_ = NULL;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int GetModelStatusRequest::kModelSpecFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

GetModelStatusRequest::GetModelStatusRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::scc_info_GetModelStatusRequest.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.GetModelStatusRequest)
}
GetModelStatusRequest::GetModelStatusRequest(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::scc_info_GetModelStatusRequest.base);
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.GetModelStatusRequest)
}
GetModelStatusRequest::GetModelStatusRequest(const GetModelStatusRequest& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_model_spec()) {
    model_spec_ = new ::tensorflow::serving::ModelSpec(*from.model_spec_);
  } else {
    model_spec_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.GetModelStatusRequest)
}

void GetModelStatusRequest::SharedCtor() {
  model_spec_ = NULL;
}

GetModelStatusRequest::~GetModelStatusRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.GetModelStatusRequest)
  SharedDtor();
}

void GetModelStatusRequest::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == NULL);
  if (this != internal_default_instance()) delete model_spec_;
}

void GetModelStatusRequest::ArenaDtor(void* object) {
  GetModelStatusRequest* _this = reinterpret_cast< GetModelStatusRequest* >(object);
  (void)_this;
}
void GetModelStatusRequest::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void GetModelStatusRequest::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* GetModelStatusRequest::descriptor() {
  ::protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const GetModelStatusRequest& GetModelStatusRequest::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::scc_info_GetModelStatusRequest.base);
  return *internal_default_instance();
}


void GetModelStatusRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.GetModelStatusRequest)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == NULL && model_spec_ != NULL) {
    delete model_spec_;
  }
  model_spec_ = NULL;
  _internal_metadata_.Clear();
}

bool GetModelStatusRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.GetModelStatusRequest)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.ModelSpec model_spec = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_model_spec()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.GetModelStatusRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.GetModelStatusRequest)
  return false;
#undef DO_
}

void GetModelStatusRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.GetModelStatusRequest)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->has_model_spec()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_model_spec(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.GetModelStatusRequest)
}

::google::protobuf::uint8* GetModelStatusRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.GetModelStatusRequest)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->has_model_spec()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_model_spec(), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.GetModelStatusRequest)
  return target;
}

size_t GetModelStatusRequest::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.GetModelStatusRequest)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->has_model_spec()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *model_spec_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void GetModelStatusRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.GetModelStatusRequest)
  GOOGLE_DCHECK_NE(&from, this);
  const GetModelStatusRequest* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const GetModelStatusRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.GetModelStatusRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.GetModelStatusRequest)
    MergeFrom(*source);
  }
}

void GetModelStatusRequest::MergeFrom(const GetModelStatusRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.GetModelStatusRequest)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_model_spec()) {
    mutable_model_spec()->::tensorflow::serving::ModelSpec::MergeFrom(from.model_spec());
  }
}

void GetModelStatusRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.GetModelStatusRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GetModelStatusRequest::CopyFrom(const GetModelStatusRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.GetModelStatusRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GetModelStatusRequest::IsInitialized() const {
  return true;
}

void GetModelStatusRequest::Swap(GetModelStatusRequest* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    GetModelStatusRequest* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void GetModelStatusRequest::UnsafeArenaSwap(GetModelStatusRequest* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void GetModelStatusRequest::InternalSwap(GetModelStatusRequest* other) {
  using std::swap;
  swap(model_spec_, other->model_spec_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata GetModelStatusRequest::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void ModelVersionStatus::InitAsDefaultInstance() {
  ::tensorflow::serving::_ModelVersionStatus_default_instance_._instance.get_mutable()->status_ = const_cast< ::tensorflow::serving::StatusProto*>(
      ::tensorflow::serving::StatusProto::internal_default_instance());
}
void ModelVersionStatus::unsafe_arena_set_allocated_status(
    ::tensorflow::serving::StatusProto* status) {
  if (GetArenaNoVirtual() == NULL) {
    delete status_;
  }
  status_ = status;
  if (status) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelVersionStatus.status)
}
void ModelVersionStatus::clear_status() {
  if (GetArenaNoVirtual() == NULL && status_ != NULL) {
    delete status_;
  }
  status_ = NULL;
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ModelVersionStatus::kVersionFieldNumber;
const int ModelVersionStatus::kStateFieldNumber;
const int ModelVersionStatus::kStatusFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ModelVersionStatus::ModelVersionStatus()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::scc_info_ModelVersionStatus.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ModelVersionStatus)
}
ModelVersionStatus::ModelVersionStatus(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::scc_info_ModelVersionStatus.base);
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ModelVersionStatus)
}
ModelVersionStatus::ModelVersionStatus(const ModelVersionStatus& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_status()) {
    status_ = new ::tensorflow::serving::StatusProto(*from.status_);
  } else {
    status_ = NULL;
  }
  ::memcpy(&version_, &from.version_,
    static_cast<size_t>(reinterpret_cast<char*>(&state_) -
    reinterpret_cast<char*>(&version_)) + sizeof(state_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ModelVersionStatus)
}

void ModelVersionStatus::SharedCtor() {
  ::memset(&status_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&state_) -
      reinterpret_cast<char*>(&status_)) + sizeof(state_));
}

ModelVersionStatus::~ModelVersionStatus() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ModelVersionStatus)
  SharedDtor();
}

void ModelVersionStatus::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == NULL);
  if (this != internal_default_instance()) delete status_;
}

void ModelVersionStatus::ArenaDtor(void* object) {
  ModelVersionStatus* _this = reinterpret_cast< ModelVersionStatus* >(object);
  (void)_this;
}
void ModelVersionStatus::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ModelVersionStatus::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* ModelVersionStatus::descriptor() {
  ::protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const ModelVersionStatus& ModelVersionStatus::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::scc_info_ModelVersionStatus.base);
  return *internal_default_instance();
}


void ModelVersionStatus::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ModelVersionStatus)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaNoVirtual() == NULL && status_ != NULL) {
    delete status_;
  }
  status_ = NULL;
  ::memset(&version_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&state_) -
      reinterpret_cast<char*>(&version_)) + sizeof(state_));
  _internal_metadata_.Clear();
}

bool ModelVersionStatus::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ModelVersionStatus)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // int64 version = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(8u /* 8 & 0xFF */)) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &version_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.ModelVersionStatus.State state = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(16u /* 16 & 0xFF */)) {
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_state(static_cast< ::tensorflow::serving::ModelVersionStatus_State >(value));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.StatusProto status = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(26u /* 26 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_status()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ModelVersionStatus)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ModelVersionStatus)
  return false;
#undef DO_
}

void ModelVersionStatus::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ModelVersionStatus)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // int64 version = 1;
  if (this->version() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(1, this->version(), output);
  }

  // .tensorflow.serving.ModelVersionStatus.State state = 2;
  if (this->state() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      2, this->state(), output);
  }

  // .tensorflow.serving.StatusProto status = 3;
  if (this->has_status()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, this->_internal_status(), output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ModelVersionStatus)
}

::google::protobuf::uint8* ModelVersionStatus::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ModelVersionStatus)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // int64 version = 1;
  if (this->version() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(1, this->version(), target);
  }

  // .tensorflow.serving.ModelVersionStatus.State state = 2;
  if (this->state() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      2, this->state(), target);
  }

  // .tensorflow.serving.StatusProto status = 3;
  if (this->has_status()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        3, this->_internal_status(), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ModelVersionStatus)
  return target;
}

size_t ModelVersionStatus::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ModelVersionStatus)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // .tensorflow.serving.StatusProto status = 3;
  if (this->has_status()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *status_);
  }

  // int64 version = 1;
  if (this->version() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->version());
  }

  // .tensorflow.serving.ModelVersionStatus.State state = 2;
  if (this->state() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->state());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void ModelVersionStatus::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ModelVersionStatus)
  GOOGLE_DCHECK_NE(&from, this);
  const ModelVersionStatus* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const ModelVersionStatus>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ModelVersionStatus)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ModelVersionStatus)
    MergeFrom(*source);
  }
}

void ModelVersionStatus::MergeFrom(const ModelVersionStatus& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ModelVersionStatus)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_status()) {
    mutable_status()->::tensorflow::serving::StatusProto::MergeFrom(from.status());
  }
  if (from.version() != 0) {
    set_version(from.version());
  }
  if (from.state() != 0) {
    set_state(from.state());
  }
}

void ModelVersionStatus::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ModelVersionStatus)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ModelVersionStatus::CopyFrom(const ModelVersionStatus& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ModelVersionStatus)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelVersionStatus::IsInitialized() const {
  return true;
}

void ModelVersionStatus::Swap(ModelVersionStatus* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ModelVersionStatus* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void ModelVersionStatus::UnsafeArenaSwap(ModelVersionStatus* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ModelVersionStatus::InternalSwap(ModelVersionStatus* other) {
  using std::swap;
  swap(status_, other->status_);
  swap(version_, other->version_);
  swap(state_, other->state_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata ModelVersionStatus::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void GetModelStatusResponse::InitAsDefaultInstance() {
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int GetModelStatusResponse::kModelVersionStatusFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

GetModelStatusResponse::GetModelStatusResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::scc_info_GetModelStatusResponse.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.GetModelStatusResponse)
}
GetModelStatusResponse::GetModelStatusResponse(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  model_version_status_(arena) {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::scc_info_GetModelStatusResponse.base);
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.GetModelStatusResponse)
}
GetModelStatusResponse::GetModelStatusResponse(const GetModelStatusResponse& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      model_version_status_(from.model_version_status_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.GetModelStatusResponse)
}

void GetModelStatusResponse::SharedCtor() {
}

GetModelStatusResponse::~GetModelStatusResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.GetModelStatusResponse)
  SharedDtor();
}

void GetModelStatusResponse::SharedDtor() {
  GOOGLE_DCHECK(GetArenaNoVirtual() == NULL);
}

void GetModelStatusResponse::ArenaDtor(void* object) {
  GetModelStatusResponse* _this = reinterpret_cast< GetModelStatusResponse* >(object);
  (void)_this;
}
void GetModelStatusResponse::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void GetModelStatusResponse::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* GetModelStatusResponse::descriptor() {
  ::protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const GetModelStatusResponse& GetModelStatusResponse::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::scc_info_GetModelStatusResponse.base);
  return *internal_default_instance();
}


void GetModelStatusResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.GetModelStatusResponse)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  model_version_status_.Clear();
  _internal_metadata_.Clear();
}

bool GetModelStatusResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.GetModelStatusResponse)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.serving.ModelVersionStatus model_version_status = 1[json_name = "model_version_status"];
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
                input, add_model_version_status()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.GetModelStatusResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.GetModelStatusResponse)
  return false;
#undef DO_
}

void GetModelStatusResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.GetModelStatusResponse)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated .tensorflow.serving.ModelVersionStatus model_version_status = 1[json_name = "model_version_status"];
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->model_version_status_size()); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1,
      this->model_version_status(static_cast<int>(i)),
      output);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), output);
  }
  // @@protoc_insertion_point(serialize_end:tensorflow.serving.GetModelStatusResponse)
}

::google::protobuf::uint8* GetModelStatusResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.GetModelStatusResponse)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated .tensorflow.serving.ModelVersionStatus model_version_status = 1[json_name = "model_version_status"];
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->model_version_status_size()); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->model_version_status(static_cast<int>(i)), deterministic, target);
  }

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.GetModelStatusResponse)
  return target;
}

size_t GetModelStatusResponse::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.GetModelStatusResponse)
  size_t total_size = 0;

  if ((_internal_metadata_.have_unknown_fields() &&  ::google::protobuf::internal::GetProto3PreserveUnknownsDefault())) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        (::google::protobuf::internal::GetProto3PreserveUnknownsDefault()   ? _internal_metadata_.unknown_fields()   : _internal_metadata_.default_instance()));
  }
  // repeated .tensorflow.serving.ModelVersionStatus model_version_status = 1[json_name = "model_version_status"];
  {
    unsigned int count = static_cast<unsigned int>(this->model_version_status_size());
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSize(
          this->model_version_status(static_cast<int>(i)));
    }
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void GetModelStatusResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.GetModelStatusResponse)
  GOOGLE_DCHECK_NE(&from, this);
  const GetModelStatusResponse* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const GetModelStatusResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.GetModelStatusResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.GetModelStatusResponse)
    MergeFrom(*source);
  }
}

void GetModelStatusResponse::MergeFrom(const GetModelStatusResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.GetModelStatusResponse)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  model_version_status_.MergeFrom(from.model_version_status_);
}

void GetModelStatusResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.GetModelStatusResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GetModelStatusResponse::CopyFrom(const GetModelStatusResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.GetModelStatusResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GetModelStatusResponse::IsInitialized() const {
  return true;
}

void GetModelStatusResponse::Swap(GetModelStatusResponse* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    GetModelStatusResponse* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void GetModelStatusResponse::UnsafeArenaSwap(GetModelStatusResponse* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void GetModelStatusResponse::InternalSwap(GetModelStatusResponse* other) {
  using std::swap;
  CastToBase(&model_version_status_)->InternalSwap(CastToBase(&other->model_version_status_));
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata GetModelStatusResponse::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_tensorflow_5fserving_2fapis_2fget_5fmodel_5fstatus_2eproto::file_level_metadata[kIndexInFileMessages];
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow
namespace google {
namespace protobuf {
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::GetModelStatusRequest* Arena::CreateMaybeMessage< ::tensorflow::serving::GetModelStatusRequest >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::GetModelStatusRequest >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::ModelVersionStatus* Arena::CreateMaybeMessage< ::tensorflow::serving::ModelVersionStatus >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::ModelVersionStatus >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::tensorflow::serving::GetModelStatusResponse* Arena::CreateMaybeMessage< ::tensorflow::serving::GetModelStatusResponse >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::GetModelStatusResponse >(arena);
}
}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)
